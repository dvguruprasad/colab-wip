{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeTug8ZmoT4lJVD07QKfQr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvguruprasad/colab-wip/blob/main/lda_async_interviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "50Foq5lV3eS8"
      },
      "outputs": [],
      "source": [
        "import csv \n",
        "\n",
        "all_data=[]\n",
        "with open('/content/query_result_2022-08-24T07_22_23.39294Z.csv', mode='r') as csv_file:\n",
        "  csv_reader = csv.DictReader(csv_file)\n",
        "  for row in csv_reader:\n",
        "    all_data.append(row)\n",
        "  all_data = all_data[1:]\n",
        "\n",
        "all = [i['data'] for i in all_data]\n",
        "not_recommended = [i['data'] for i in all_data if i['recommendation'] == 'Not Recommended']\n",
        "recommended = [i['data'] for i in all_data if i['recommendation'] == 'Recommended']\n",
        "\n",
        "corpus = all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bidP0CbF4JTq",
        "outputId": "73e4cc5d-ab60-4107-cb6f-aed877e960b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_sample = corpus[0]\n",
        "print('original document: ')\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print('\\n\\n tokenized and lemmatized document: ')\n",
        "print(preprocess(doc_sample))\n",
        "\n",
        "processed_docs = [preprocess(doc) for doc in corpus]\n",
        "print(processed_docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgkAPQE_4_gS",
        "outputId": "1d7207f8-7af3-4352-84cb-bb56ebc0ac14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original document: \n",
            "['', 'with', 'warehouse', 'management', 'systems', 'such', 'as', \"let's\", 'see', 'the', 'RF', 'scanners', \"I've\", 'used', 'them', 'for', 'over', 'a', 'year', \"I've\", 'had', 'plenty', 'of', 'experience', \"I've\", 'been', 'trained', 'to', 'do', 'most', 'of', 'the', 'functions', 'on', 'them', 'other', 'than', 'like', 'some', 'of', 'the', 'more', 'complicated', 'ones', 'most', 'of', 'the', 'functions', 'our', 'church', 'I', 'was', 'trained', 'on', 'with', 'RF', 'scanner', 'were', 'moving', '', 'from', 'one', 'slide', 'to', 'another', 'and', 'or', 'cakey', 'in', 'receiving', 'items', 'and', 'moving', 'them', 'to', 'pallet', 'slots', 'or', 'inputting', 'from', 'a', 'palette', 'slot', 'to', 'a', 'pixel', 'lat', 'my', 'Initiative', 'for', 'learning', 'something', 'new', 'was', 'the', 'simple', 'fact', 'of', '', 'anything', 'I', 'try', 'to', 'learn', 'something', 'new', 'to', 'me', 'I', 'look', 'at', 'it', 'and', 'think', 'about', 'what', 'I', 'can', 'use', 'it', 'for', 'in', 'the', 'future', 'such', 'as', 'customer', 'service', '', 'applications', 'of', 'electronic', 'equipment', 'such', 'as', 'RF', 'scanners', 'the', 'computer', 'database', 'system', 'that', 'the', 'Distribution', 'Center', 'uses', 'say', 'a', 'computer', 'that', 'can', 'handle', 'a', 'multitude', 'of', 'functions', 'I', 'make', 'sure', 'that', 'I', 'base', 'my', 'decisions', 'off', 'of', 'learning', 'something', 'new', 'something', 'that', 'I', 'can', 'use', 'later', 'in', 'life', 'either', 'that', 'being', 'at', 'another', 'job', 'or', 'at', 'home', '', 'helping', 'my', 'family', 'and', 'or', 'my', 'friends', 'would', 'their', 'needs', 'making', 'sure', 'that', 'they', 'understand', 'that', \"it's\", 'more', 'of', 'a', 'personal', 'experience', 'to', 'make', 'sure', 'that', 'the', 'co-worker', 'and', 'or', 'customers', 'needs', 'are', 'satisfied', 'in', 'a', 'timely', 'manner', 'while', 'also', 'following', 'protocol', 'on', 'the', 'topic', 'and', 'are', 'asking', 'more', 'questions', 'to', 'collect', 'further', 'information', 'on', 'said', 'subject', '', \"I'll\", 'make', 'sure', 'to', 'ask', 'the', 'co-worker', 'and', 'or', 'customer', 'about', 'what', 'their', 'needs', 'and', 'from', 'my', 'collection', 'of', 'information', 'that', 'I', 'received', 'from', 'the', 'customer', 'and', 'co-worker', \"I'll\", 'take', 'that', 'and', 'determine', 'the', 'appropriate', 'action', 'that', 'I', 'need', 'to', 'take', 'in', 'order', 'to', 'help', 'that', 'co-worker', 'or', 'customer', 'some', 'ways', 'I', 'would', 'establish', 'credibility', 'and', 'trust', 'with', 'the', 'customer', 'is', 'ask', 'him', 'a', 'few', 'questions', 'kind', 'of', 'sort', 'of', 'get', 'to', 'know', 'them', 'a', 'little', 'also', 'determining', 'what', 'product', 'they', 'may', 'need', 'at', 'that', 'given', 'time', 'of', 'course', 'it', 'could', 'depend', 'on', 'you', 'know', 'if', \"it's\", 'a', 'medical', 'product', 'you', 'know', 'such', 'as', 'a', 'a', '', \"let's\", 'say', 'the', 'portable', 'EKGs', 'they', 'have', 'a', 'computer', 'of', 'a', 'certain', 'type', 'you', 'would', 'also', 'need', 'to', 'ask', 'about', 'you', 'know', 'what', 'type', 'of', 'purpose', 'or', 'what', 'the', 'reason', 'for', 'the', 'product', 'needed', 'or', '', 'you', 'know', 'making', 'sure', 'that', 'you', 'understand', 'their', 'needs', 'and', 'what', 'they', 'want', 'and', 'make', 'sure', 'you', 'understand', 'the', 'reasoning', 'behind', 'those', 'needs', 'my', 'previous', 'work', 'experience', 'is', 'war', 'at', 'Tractor', 'Supply', 'and', 'at', 'the', 'Distribution', 'Center', 'that', \"I'm\", 'applying', 'for', 'my', 'main', 'goal', 'was', 'to', 'get', 'done', 'with', 'college', 'and', 'get', 'my', 'diploma', 'in', 'mechatronic', 'engineering', 'or', 'industrial', 'electrician', 'I', 'have', 'since', 'finished', 'schooling', 'and', 'awaiting', 'my', 'diploma', 'to', 'arrive', '', 'and', 'many', 'things', 'interest', 'me', 'so', 'ology', 'solving', 'puzzles', 'and', 'real', 'life', 'meaning', 'you', 'know', 'you', 'have', 'an', 'item', 'here', 'that', 'needs', 'to', 'get', 'moved', 'somewhere', 'else', 'but', \"it's\", 'complicated', 'to', 'get', 'it', 'there', 'I', 'like', 'having', 'a', 'complicated', 'puzzle', 'to', 'solve', 'as', 'well', 'as', 'working', 'in', 'teams', 'and', 'solving', 'in', 'tow', 'with', 'other', 'people', 'my', 'reason', 'for', 'being', 'excited', 'to', 'work', 'at', 'Best', 'Buy', 'is', 'that', 'I', 'have', 'previous', 'experience', 'and', 'prior', 'knowledge', 'in', 'this', 'career', 'field', 'I', 'was', 'also', 'working', 'in', 'at', 'Best', 'Buy', 'at', 'the', 'distribution', 'center', 'and', 'going', 'to', 'school', 'at', 'the', 'same', 'time', 'but', 'it', 'became', 'hard', 'to', 'balance', 'the', 'two', 'and', 'I', 'had', 'to', 'focus', 'on', 'getting', 'School', 'done']\n",
            "\n",
            "\n",
            " tokenized and lemmatized document: \n",
            "['warehous', 'manag', 'system', 'scanner', 'year', 'plenti', 'experi', 'train', 'function', 'like', 'complic', 'one', 'function', 'church', 'train', 'scanner', 'move', 'slide', 'cakey', 'receiv', 'item', 'move', 'pallet', 'slot', 'input', 'palett', 'slot', 'pixel', 'initi', 'learn', 'simpl', 'fact', 'learn', 'look', 'think', 'futur', 'custom', 'servic', 'applic', 'electron', 'equip', 'scanner', 'databas', 'distribut', 'center', 'use', 'handl', 'multitud', 'function', 'sure', 'base', 'decis', 'learn', 'later', 'life', 'home', 'help', 'famili', 'friend', 'need', 'make', 'sure', 'understand', 'person', 'experi', 'sure', 'worker', 'custom', 'need', 'satisfi', 'time', 'manner', 'follow', 'protocol', 'topic', 'ask', 'question', 'collect', 'inform', 'say', 'subject', 'sure', 'worker', 'custom', 'need', 'collect', 'inform', 'receiv', 'custom', 'worker', 'determin', 'appropri', 'action', 'need', 'order', 'help', 'worker', 'custom', 'way', 'establish', 'credibl', 'trust', 'custom', 'question', 'kind', 'sort', 'know', 'littl', 'determin', 'product', 'need', 'give', 'time', 'cours', 'depend', 'know', 'medic', 'product', 'know', 'portabl', 'ekg', 'certain', 'type', 'need', 'know', 'type', 'purpos', 'reason', 'product', 'need', 'know', 'make', 'sure', 'understand', 'need', 'want', 'sure', 'understand', 'reason', 'need', 'previou', 'work', 'experi', 'tractor', 'suppli', 'distribut', 'center', 'appli', 'main', 'goal', 'colleg', 'diploma', 'mechatron', 'engin', 'industri', 'electrician', 'finish', 'school', 'await', 'diploma', 'arriv', 'thing', 'olog', 'solv', 'puzzl', 'real', 'life', 'mean', 'know', 'item', 'need', 'move', 'complic', 'like', 'have', 'complic', 'puzzl', 'solv', 'work', 'team', 'solv', 'peopl', 'reason', 'excit', 'work', 'best', 'previou', 'experi', 'prior', 'knowledg', 'career', 'field', 'work', 'best', 'distribut', 'center', 'go', 'school', 'time', 'hard', 'balanc', 'focu', 'get', 'school']\n",
            "['warehous', 'manag', 'system', 'scanner', 'year', 'plenti', 'experi', 'train', 'function', 'like', 'complic', 'one', 'function', 'church', 'train', 'scanner', 'move', 'slide', 'cakey', 'receiv', 'item', 'move', 'pallet', 'slot', 'input', 'palett', 'slot', 'pixel', 'initi', 'learn', 'simpl', 'fact', 'learn', 'look', 'think', 'futur', 'custom', 'servic', 'applic', 'electron', 'equip', 'scanner', 'databas', 'distribut', 'center', 'use', 'handl', 'multitud', 'function', 'sure', 'base', 'decis', 'learn', 'later', 'life', 'home', 'help', 'famili', 'friend', 'need', 'make', 'sure', 'understand', 'person', 'experi', 'sure', 'worker', 'custom', 'need', 'satisfi', 'time', 'manner', 'follow', 'protocol', 'topic', 'ask', 'question', 'collect', 'inform', 'say', 'subject', 'sure', 'worker', 'custom', 'need', 'collect', 'inform', 'receiv', 'custom', 'worker', 'determin', 'appropri', 'action', 'need', 'order', 'help', 'worker', 'custom', 'way', 'establish', 'credibl', 'trust', 'custom', 'question', 'kind', 'sort', 'know', 'littl', 'determin', 'product', 'need', 'give', 'time', 'cours', 'depend', 'know', 'medic', 'product', 'know', 'portabl', 'ekg', 'certain', 'type', 'need', 'know', 'type', 'purpos', 'reason', 'product', 'need', 'know', 'make', 'sure', 'understand', 'need', 'want', 'sure', 'understand', 'reason', 'need', 'previou', 'work', 'experi', 'tractor', 'suppli', 'distribut', 'center', 'appli', 'main', 'goal', 'colleg', 'diploma', 'mechatron', 'engin', 'industri', 'electrician', 'finish', 'school', 'await', 'diploma', 'arriv', 'thing', 'olog', 'solv', 'puzzl', 'real', 'life', 'mean', 'know', 'item', 'need', 'move', 'complic', 'like', 'have', 'complic', 'puzzl', 'solv', 'work', 'team', 'solv', 'peopl', 'reason', 'excit', 'work', 'best', 'previou', 'experi', 'prior', 'knowledg', 'career', 'field', 'work', 'best', 'distribut', 'center', 'go', 'school', 'time', 'hard', 'balanc', 'focu', 'get', 'school']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXCJfJK355Zl",
        "outputId": "e18d524f-79ff-4487-dc17-9ddc3d70932f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 action\n",
            "1 appli\n",
            "2 applic\n",
            "3 appropri\n",
            "4 arriv\n",
            "5 ask\n",
            "6 await\n",
            "7 balanc\n",
            "8 base\n",
            "9 best\n",
            "10 cakey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "print(len(bow_corpus))\n",
        "\n",
        "bow_doc_10 = bow_corpus[10]\n",
        "for i in range(len(bow_doc_10)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_10[i][0], \n",
        "                                               dictionary[bow_doc_10[i][0]], bow_doc_10[i][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqf6oqKg6LqZ",
        "outputId": "cff4d30b-26fd-4022-f07b-bc1e16c5229f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "927\n",
            "Word 5 (\"ask\") appears 2 time.\n",
            "Word 8 (\"career\") appears 2 time.\n",
            "Word 10 (\"certain\") appears 1 time.\n",
            "Word 27 (\"field\") appears 2 time.\n",
            "Word 30 (\"follow\") appears 1 time.\n",
            "Word 31 (\"friend\") appears 1 time.\n",
            "Word 32 (\"function\") appears 1 time.\n",
            "Word 34 (\"get\") appears 3 time.\n",
            "Word 35 (\"give\") appears 2 time.\n",
            "Word 39 (\"have\") appears 1 time.\n",
            "Word 40 (\"home\") appears 2 time.\n",
            "Word 43 (\"initi\") appears 4 time.\n",
            "Word 46 (\"knowledg\") appears 2 time.\n",
            "Word 47 (\"later\") appears 3 time.\n",
            "Word 48 (\"life\") appears 1 time.\n",
            "Word 52 (\"mean\") appears 1 time.\n",
            "Word 56 (\"order\") appears 1 time.\n",
            "Word 67 (\"school\") appears 1 time.\n",
            "Word 68 (\"servic\") appears 1 time.\n",
            "Word 75 (\"team\") appears 6 time.\n",
            "Word 79 (\"type\") appears 1 time.\n",
            "Word 80 (\"understand\") appears 5 time.\n",
            "Word 86 (\"activ\") appears 1 time.\n",
            "Word 89 (\"articl\") appears 1 time.\n",
            "Word 93 (\"build\") appears 3 time.\n",
            "Word 103 (\"earli\") appears 1 time.\n",
            "Word 106 (\"enjoy\") appears 1 time.\n",
            "Word 112 (\"gain\") appears 1 time.\n",
            "Word 121 (\"morn\") appears 2 time.\n",
            "Word 123 (\"normal\") appears 1 time.\n",
            "Word 125 (\"older\") appears 2 time.\n",
            "Word 126 (\"onlin\") appears 1 time.\n",
            "Word 128 (\"pace\") appears 1 time.\n",
            "Word 131 (\"phone\") appears 2 time.\n",
            "Word 141 (\"research\") appears 2 time.\n",
            "Word 144 (\"show\") appears 1 time.\n",
            "Word 150 (\"test\") appears 3 time.\n",
            "Word 161 (\"bring\") appears 7 time.\n",
            "Word 167 (\"creat\") appears 1 time.\n",
            "Word 168 (\"current\") appears 1 time.\n",
            "Word 169 (\"definit\") appears 6 time.\n",
            "Word 170 (\"develop\") appears 1 time.\n",
            "Word 171 (\"devic\") appears 4 time.\n",
            "Word 172 (\"differ\") appears 2 time.\n",
            "Word 188 (\"hardwar\") appears 1 time.\n",
            "Word 189 (\"high\") appears 1 time.\n",
            "Word 191 (\"hope\") appears 1 time.\n",
            "Word 203 (\"note\") appears 1 time.\n",
            "Word 209 (\"possibl\") appears 1 time.\n",
            "Word 213 (\"program\") appears 1 time.\n",
            "Word 217 (\"respons\") appears 1 time.\n",
            "Word 218 (\"run\") appears 1 time.\n",
            "Word 222 (\"softwar\") appears 2 time.\n",
            "Word 224 (\"specif\") appears 1 time.\n",
            "Word 225 (\"stay\") appears 1 time.\n",
            "Word 226 (\"stop\") appears 1 time.\n",
            "Word 230 (\"task\") appears 6 time.\n",
            "Word 232 (\"usual\") appears 1 time.\n",
            "Word 243 (\"chang\") appears 1 time.\n",
            "Word 247 (\"complet\") appears 3 time.\n",
            "Word 252 (\"date\") appears 1 time.\n",
            "Word 253 (\"day\") appears 1 time.\n",
            "Word 260 (\"great\") appears 1 time.\n",
            "Word 266 (\"includ\") appears 1 time.\n",
            "Word 268 (\"iphon\") appears 1 time.\n",
            "Word 271 (\"latest\") appears 1 time.\n",
            "Word 273 (\"mayb\") appears 4 time.\n",
            "Word 274 (\"member\") appears 1 time.\n",
            "Word 276 (\"minut\") appears 1 time.\n",
            "Word 280 (\"okay\") appears 1 time.\n",
            "Word 282 (\"place\") appears 1 time.\n",
            "Word 289 (\"rememb\") appears 1 time.\n",
            "Word 294 (\"sign\") appears 1 time.\n",
            "Word 300 (\"take\") appears 2 time.\n",
            "Word 301 (\"teach\") appears 1 time.\n",
            "Word 303 (\"video\") appears 1 time.\n",
            "Word 305 (\"write\") appears 3 time.\n",
            "Word 306 (\"account\") appears 2 time.\n",
            "Word 308 (\"appl\") appears 7 time.\n",
            "Word 314 (\"bunch\") appears 1 time.\n",
            "Word 315 (\"busi\") appears 1 time.\n",
            "Word 316 (\"care\") appears 1 time.\n",
            "Word 320 (\"coupl\") appears 2 time.\n",
            "Word 326 (\"easier\") appears 1 time.\n",
            "Word 337 (\"grow\") appears 1 time.\n",
            "Word 338 (\"guy\") appears 4 time.\n",
            "Word 339 (\"hand\") appears 1 time.\n",
            "Word 341 (\"happi\") appears 1 time.\n",
            "Word 352 (\"merchandis\") appears 1 time.\n",
            "Word 353 (\"moment\") appears 1 time.\n",
            "Word 358 (\"provid\") appears 2 time.\n",
            "Word 360 (\"reach\") appears 1 time.\n",
            "Word 362 (\"return\") appears 2 time.\n",
            "Word 367 (\"share\") appears 1 time.\n",
            "Word 368 (\"shift\") appears 2 time.\n",
            "Word 387 (\"youtub\") appears 2 time.\n",
            "Word 388 (\"actual\") appears 12 time.\n",
            "Word 393 (\"familiar\") appears 1 time.\n",
            "Word 395 (\"graduat\") appears 1 time.\n",
            "Word 398 (\"ipad\") appears 4 time.\n",
            "Word 400 (\"origin\") appears 1 time.\n",
            "Word 402 (\"role\") appears 8 time.\n",
            "Word 404 (\"schedul\") appears 2 time.\n",
            "Word 408 (\"store\") appears 5 time.\n",
            "Word 412 (\"watch\") appears 1 time.\n",
            "Word 414 (\"area\") appears 3 time.\n",
            "Word 420 (\"email\") appears 6 time.\n",
            "Word 425 (\"leav\") appears 4 time.\n",
            "Word 427 (\"market\") appears 3 time.\n",
            "Word 436 (\"pull\") appears 1 time.\n",
            "Word 437 (\"purchas\") appears 1 time.\n",
            "Word 440 (\"send\") appears 1 time.\n",
            "Word 446 (\"user\") appears 1 time.\n",
            "Word 448 (\"yeah\") appears 6 time.\n",
            "Word 449 (\"ahead\") appears 1 time.\n",
            "Word 456 (\"everyday\") appears 1 time.\n",
            "Word 464 (\"notic\") appears 1 time.\n",
            "Word 477 (\"wait\") appears 1 time.\n",
            "Word 495 (\"supervisor\") appears 3 time.\n",
            "Word 496 (\"wouldn\") appears 1 time.\n",
            "Word 511 (\"cool\") appears 1 time.\n",
            "Word 512 (\"correctli\") appears 1 time.\n",
            "Word 516 (\"display\") appears 1 time.\n",
            "Word 518 (\"drive\") appears 1 time.\n",
            "Word 523 (\"floor\") appears 1 time.\n",
            "Word 561 (\"walk\") appears 2 time.\n",
            "Word 563 (\"wasn\") appears 2 time.\n",
            "Word 566 (\"android\") appears 1 time.\n",
            "Word 567 (\"appreci\") appears 2 time.\n",
            "Word 568 (\"board\") appears 1 time.\n",
            "Word 569 (\"book\") appears 1 time.\n",
            "Word 570 (\"buy\") appears 1 time.\n",
            "Word 571 (\"case\") appears 1 time.\n",
            "Word 572 (\"color\") appears 1 time.\n",
            "Word 573 (\"crazi\") appears 1 time.\n",
            "Word 574 (\"daili\") appears 1 time.\n",
            "Word 575 (\"deep\") appears 2 time.\n",
            "Word 576 (\"desktop\") appears 1 time.\n",
            "Word 577 (\"earlier\") appears 2 time.\n",
            "Word 578 (\"except\") appears 1 time.\n",
            "Word 579 (\"explor\") appears 1 time.\n",
            "Word 580 (\"faster\") appears 1 time.\n",
            "Word 581 (\"feedback\") appears 1 time.\n",
            "Word 582 (\"fresh\") appears 1 time.\n",
            "Word 583 (\"galaxi\") appears 1 time.\n",
            "Word 584 (\"guid\") appears 2 time.\n",
            "Word 585 (\"hour\") appears 1 time.\n",
            "Word 586 (\"huge\") appears 1 time.\n",
            "Word 587 (\"imag\") appears 1 time.\n",
            "Word 588 (\"incorpor\") appears 1 time.\n",
            "Word 589 (\"instruct\") appears 1 time.\n",
            "Word 590 (\"list\") appears 2 time.\n",
            "Word 591 (\"long\") appears 1 time.\n",
            "Word 592 (\"mention\") appears 1 time.\n",
            "Word 593 (\"messag\") appears 1 time.\n",
            "Word 594 (\"newest\") appears 1 time.\n",
            "Word 595 (\"overtim\") appears 1 time.\n",
            "Word 596 (\"own\") appears 1 time.\n",
            "Word 597 (\"passion\") appears 1 time.\n",
            "Word 598 (\"password\") appears 6 time.\n",
            "Word 599 (\"platform\") appears 1 time.\n",
            "Word 600 (\"push\") appears 1 time.\n",
            "Word 601 (\"race\") appears 1 time.\n",
            "Word 602 (\"remot\") appears 2 time.\n",
            "Word 603 (\"repeat\") appears 1 time.\n",
            "Word 604 (\"retail\") appears 3 time.\n",
            "Word 605 (\"review\") appears 1 time.\n",
            "Word 606 (\"rout\") appears 1 time.\n",
            "Word 607 (\"samsung\") appears 2 time.\n",
            "Word 608 (\"screen\") appears 1 time.\n",
            "Word 609 (\"soon\") appears 1 time.\n",
            "Word 610 (\"sorri\") appears 1 time.\n",
            "Word 611 (\"speed\") appears 1 time.\n",
            "Word 612 (\"technician\") appears 1 time.\n",
            "Word 613 (\"till\") appears 1 time.\n",
            "Word 614 (\"today\") appears 2 time.\n",
            "Word 615 (\"travel\") appears 1 time.\n",
            "Word 616 (\"ultim\") appears 1 time.\n",
            "Word 617 (\"websit\") appears 2 time.\n",
            "Word 618 (\"weekend\") appears 1 time.\n",
            "Word 619 (\"window\") appears 1 time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora, models\n",
        "tfidf = models.TfidfModel(bow_corpus)\n",
        "corpus_tfidf = tfidf[bow_corpus]\n",
        "from pprint import pprint\n",
        "for doc in corpus_tfidf:\n",
        "    pprint(doc)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tdc2XGIr733n",
        "outputId": "329c56b9-3ec4-44dd-9bff-602bc94b5fc6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.09228620446161498),\n",
            " (1, 0.06312257899318931),\n",
            " (2, 0.09156118576545902),\n",
            " (3, 0.10382662869668012),\n",
            " (4, 0.11573180004869624),\n",
            " (5, 0.02388169575330429),\n",
            " (6, 0.11573180004869624),\n",
            " (7, 0.050857136061968185),\n",
            " (8, 0.059066241175054775),\n",
            " (9, 0.23684540327716644),\n",
            " (10, 0.042770554141443894),\n",
            " (11, 0.104934751350226),\n",
            " (12, 0.18457240892322996),\n",
            " (13, 0.05592535090437536),\n",
            " (14, 0.3424328729578433),\n",
            " (15, 0.050324884049593524),\n",
            " (16, 0.0542707292059491),\n",
            " (17, 0.08882788660932817),\n",
            " (18, 0.05176624166411207),\n",
            " (19, 0.1085414584118982),\n",
            " (20, 0.3379146879400812),\n",
            " (21, 0.0420986308762586),\n",
            " (22, 0.08458272649848059),\n",
            " (23, 0.0705016142593262),\n",
            " (24, 0.0476385074209489),\n",
            " (25, 0.06719906210564801),\n",
            " (26, 0.0420986308762586),\n",
            " (27, 0.060274714840865724),\n",
            " (28, 0.041966071891168605),\n",
            " (29, 0.06981071731637198),\n",
            " (30, 0.055086386248110235),\n",
            " (31, 0.035786867105320405),\n",
            " (32, 0.30219917388403283),\n",
            " (33, 0.059066241175054775),\n",
            " (34, 0.021219923466469295),\n",
            " (35, 0.03023777917843186),\n",
            " (36, 0.033818322152752066),\n",
            " (37, 0.05954367877296502),\n",
            " (38, 0.041834108678808365),\n",
            " (39, 0.027771812054091943),\n",
            " (40, 0.03654673338389647),\n",
            " (41, 0.07585489702371964),\n",
            " (42, 0.07397987651343932),\n",
            " (43, 0.04747849740464606),\n",
            " (44, 0.09537977519695083),\n",
            " (45, 0.105408794078826),\n",
            " (46, 0.03979957968161007),\n",
            " (47, 0.059785340757124446),\n",
            " (48, 0.07030169464045766),\n",
            " (49, 0.05657069040556665),\n",
            " (50, 0.05084323371070199),\n",
            " (51, 0.07585489702371964),\n",
            " (52, 0.029021437465007294),\n",
            " (53, 0.11120566396281702),\n",
            " (54, 0.15203593361300874),\n",
            " (55, 0.07193417960986959),\n",
            " (56, 0.0391916539212196),\n",
            " (57, 0.09705804713050648),\n",
            " (58, 0.0997702908785456),\n",
            " (59, 0.11581109192871172),\n",
            " (60, 0.09883809304923763),\n",
            " (61, 0.104934751350226),\n",
            " (62, 0.06783052225639147),\n",
            " (63, 0.14486223786959446),\n",
            " (64, 0.12358753114307913),\n",
            " (65, 0.07941826602680019),\n",
            " (66, 0.3471954001460887),\n",
            " (67, 0.1026657799696172),\n",
            " (68, 0.022013533002187575),\n",
            " (69, 0.06394972567170354),\n",
            " (70, 0.12354913523608621),\n",
            " (71, 0.05308821643071153),\n",
            " (72, 0.11120566396281702),\n",
            " (73, 0.09793458282878303),\n",
            " (74, 0.07543841109985565),\n",
            " (75, 0.02633924670354856),\n",
            " (76, 0.09302957999820989),\n",
            " (77, 0.1081406136428617),\n",
            " (78, 0.0391916539212196),\n",
            " (79, 0.07265522943056911),\n",
            " (80, 0.0785529089740304),\n",
            " (81, 0.08515287577849036),\n",
            " (82, 0.06597547817344696),\n",
            " (83, 0.040170470069914276)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=8, workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "BjGi9s8t8hgJ",
        "outputId": "d061d467-46de-449b-8f5b-7ccfe51f5a30"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "Process ForkPoolWorker-8:\n",
            "Process ForkPoolWorker-7:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 105, in worker\n",
            "    initializer(*initargs)\n",
            "  File \"<__array_function__ internals>\", line 6, in dot\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 333, in worker_e_step\n",
            "    worker_lda.do_estep(chunk)  # TODO: auto-tune alpha?\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 725, in do_estep\n",
            "    gamma, sstats = self.inference(chunk, collect_sstats=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\", line 676, in inference\n",
            "    gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\", line 330, in worker_e_step\n",
            "    chunk_no, chunk, worker_lda = input_queue.get()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
            "    res = self._recv_bytes()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-632b5a25e206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;31m# wait for all outstanding jobs to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mprocess_result_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreallen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mprocess_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \"\"\"\n\u001b[1;32m    267\u001b[0m                 \u001b[0mmerged_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m                     \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0mqueue_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthose\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_list\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mare\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mreadable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         '''\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_WaitSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEVENT_READ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fd_to_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# read-only mapping returned by get_map()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SelectorMapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fileobj_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, selector)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84DPYyRp8tQP",
        "outputId": "5eb56f81-0062-491a-b535-945713e5aa2a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 \n",
            "Words: 0.014*\"phone\" + 0.009*\"task\" + 0.009*\"mean\" + 0.008*\"ask\" + 0.008*\"take\" + 0.008*\"speak\" + 0.008*\"understand\" + 0.007*\"actual\" + 0.007*\"yeah\" + 0.007*\"pretti\"\n",
            "Topic: 1 \n",
            "Words: 0.014*\"probabl\" + 0.012*\"phone\" + 0.012*\"actual\" + 0.011*\"differ\" + 0.010*\"task\" + 0.008*\"yeah\" + 0.008*\"goal\" + 0.008*\"comput\" + 0.007*\"play\" + 0.007*\"get\"\n",
            "Topic: 2 \n",
            "Words: 0.010*\"store\" + 0.010*\"understand\" + 0.009*\"differ\" + 0.009*\"servic\" + 0.008*\"great\" + 0.008*\"team\" + 0.008*\"basic\" + 0.008*\"take\" + 0.007*\"situat\" + 0.007*\"pretti\"\n",
            "Topic: 3 \n",
            "Words: 0.013*\"actual\" + 0.013*\"yeah\" + 0.012*\"team\" + 0.011*\"definit\" + 0.009*\"goal\" + 0.008*\"phone\" + 0.008*\"servic\" + 0.008*\"get\" + 0.008*\"speak\" + 0.007*\"differ\"\n",
            "Topic: 4 \n",
            "Words: 0.015*\"actual\" + 0.011*\"yeah\" + 0.010*\"understand\" + 0.009*\"make\" + 0.009*\"phone\" + 0.009*\"issu\" + 0.008*\"enjoy\" + 0.007*\"differ\" + 0.007*\"problem\" + 0.007*\"usual\"\n",
            "Topic: 5 \n",
            "Words: 0.011*\"pretti\" + 0.011*\"yeah\" + 0.010*\"store\" + 0.008*\"ask\" + 0.008*\"stay\" + 0.008*\"comput\" + 0.007*\"get\" + 0.007*\"problem\" + 0.007*\"understand\" + 0.007*\"listen\"\n",
            "Topic: 6 \n",
            "Words: 0.010*\"differ\" + 0.009*\"problem\" + 0.009*\"phone\" + 0.008*\"mayb\" + 0.008*\"store\" + 0.008*\"import\" + 0.007*\"play\" + 0.007*\"take\" + 0.007*\"get\" + 0.007*\"favorit\"\n",
            "Topic: 7 \n",
            "Words: 0.012*\"differ\" + 0.011*\"actual\" + 0.010*\"servic\" + 0.009*\"basic\" + 0.008*\"yeah\" + 0.008*\"store\" + 0.007*\"video\" + 0.007*\"phone\" + 0.007*\"team\" + 0.007*\"listen\"\n",
            "Topic: 8 \n",
            "Words: 0.013*\"actual\" + 0.012*\"yeah\" + 0.010*\"differ\" + 0.008*\"take\" + 0.008*\"make\" + 0.008*\"great\" + 0.007*\"play\" + 0.007*\"mayb\" + 0.007*\"guess\" + 0.007*\"phone\"\n",
            "Topic: 9 \n",
            "Words: 0.010*\"phone\" + 0.009*\"differ\" + 0.008*\"build\" + 0.008*\"yeah\" + 0.007*\"order\" + 0.007*\"truck\" + 0.007*\"actual\" + 0.007*\"situat\" + 0.006*\"team\" + 0.006*\"okay\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, id2word=dictionary, passes=20, workers=4)\n",
        "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
        "    print('Topic: {} Word: {}'.format(idx, topic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sekb-EOe9J0m",
        "outputId": "0807488c-c03c-486a-ab35-04980e979055"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: 0 Word: 0.131*\"unprofession\" + 0.104*\"back\" + 0.022*\"sing\" + 0.003*\"request\" + 0.003*\"draw\" + 0.003*\"fulli\" + 0.001*\"volunt\" + 0.001*\"resolv\" + 0.001*\"haven\" + 0.001*\"kitchen\"\n",
            "Topic: 1 Word: 0.001*\"solut\" + 0.001*\"fastest\" + 0.001*\"choic\" + 0.001*\"daughter\" + 0.001*\"footbal\" + 0.001*\"basketbal\" + 0.001*\"night\" + 0.001*\"appli\" + 0.001*\"worri\" + 0.001*\"shift\"\n",
            "Topic: 2 Word: 0.009*\"definit\" + 0.009*\"listen\" + 0.008*\"comput\" + 0.008*\"somebodi\" + 0.007*\"import\" + 0.007*\"electron\" + 0.006*\"type\" + 0.006*\"complet\" + 0.006*\"googl\" + 0.006*\"leav\"\n",
            "Topic: 3 Word: 0.187*\"holiday\" + 0.001*\"black\" + 0.001*\"merchandis\" + 0.001*\"happi\" + 0.001*\"offic\" + 0.001*\"low\" + 0.001*\"descript\" + 0.001*\"star\" + 0.001*\"laptop\" + 0.001*\"repres\"\n",
            "Topic: 4 Word: 0.192*\"bond\" + 0.078*\"greet\" + 0.026*\"seek\" + 0.019*\"macbook\" + 0.014*\"accomplish\" + 0.009*\"inappropri\" + 0.009*\"interpret\" + 0.009*\"round\" + 0.006*\"privaci\" + 0.004*\"consult\"\n",
            "Topic: 5 Word: 0.033*\"smartphon\" + 0.030*\"travel\" + 0.002*\"job\" + 0.001*\"pizza\" + 0.001*\"truck\" + 0.001*\"mood\" + 0.001*\"definit\" + 0.001*\"encourag\" + 0.001*\"warehous\" + 0.001*\"crew\"\n",
            "Topic: 6 Word: 0.002*\"click\" + 0.002*\"success\" + 0.001*\"knock\" + 0.001*\"remind\" + 0.001*\"out\" + 0.001*\"trade\" + 0.001*\"bachelor\" + 0.001*\"speed\" + 0.001*\"credit\" + 0.001*\"card\"\n",
            "Topic: 7 Word: 0.001*\"extent\" + 0.001*\"onlin\" + 0.001*\"groceri\" + 0.001*\"definit\" + 0.001*\"display\" + 0.001*\"procedur\" + 0.001*\"walmart\" + 0.001*\"teammat\" + 0.001*\"directli\" + 0.001*\"tip\"\n",
            "Topic: 8 Word: 0.004*\"repres\" + 0.003*\"box\" + 0.003*\"detail\" + 0.003*\"direct\" + 0.002*\"faster\" + 0.002*\"overtim\" + 0.001*\"stool\" + 0.001*\"sleep\" + 0.001*\"till\" + 0.001*\"issu\"\n",
            "Topic: 9 Word: 0.042*\"face\" + 0.030*\"privaci\" + 0.027*\"individu\" + 0.026*\"box\" + 0.024*\"bodi\" + 0.024*\"constantli\" + 0.024*\"forklift\" + 0.022*\"accomplish\" + 0.020*\"resolv\" + 0.018*\"frustrat\"\n",
            "Topic: 10 Word: 0.002*\"lunch\" + 0.002*\"object\" + 0.002*\"manufactur\" + 0.002*\"zone\" + 0.001*\"stone\" + 0.001*\"consol\" + 0.001*\"demonstr\" + 0.001*\"holiday\" + 0.001*\"camp\" + 0.001*\"clean\"\n",
            "Topic: 11 Word: 0.002*\"clerk\" + 0.001*\"select\" + 0.001*\"lead\" + 0.001*\"succeed\" + 0.001*\"children\" + 0.001*\"district\" + 0.001*\"depart\" + 0.001*\"microphon\" + 0.001*\"process\" + 0.001*\"accomplish\"\n",
            "Topic: 12 Word: 0.001*\"arriv\" + 0.001*\"slowli\" + 0.001*\"pack\" + 0.001*\"water\" + 0.001*\"wake\" + 0.001*\"earlier\" + 0.001*\"park\" + 0.001*\"local\" + 0.001*\"websit\" + 0.001*\"move\"\n",
            "Topic: 13 Word: 0.001*\"space\" + 0.001*\"drink\" + 0.001*\"tend\" + 0.001*\"articl\" + 0.001*\"cashier\" + 0.001*\"post\" + 0.001*\"special\" + 0.001*\"make\" + 0.001*\"class\" + 0.001*\"wrong\"\n",
            "Topic: 14 Word: 0.048*\"book\" + 0.035*\"money\" + 0.028*\"nice\" + 0.025*\"electron\" + 0.021*\"life\" + 0.001*\"lay\" + 0.001*\"guy\" + 0.001*\"militari\" + 0.001*\"proud\" + 0.001*\"guess\"\n",
            "Topic: 15 Word: 0.002*\"consult\" + 0.001*\"heavi\" + 0.001*\"file\" + 0.001*\"motherboard\" + 0.001*\"felt\" + 0.001*\"agent\" + 0.001*\"speaker\" + 0.001*\"power\" + 0.001*\"instal\" + 0.001*\"happi\"\n",
            "Topic: 16 Word: 0.043*\"walmart\" + 0.031*\"act\" + 0.029*\"total\" + 0.001*\"unfamiliar\" + 0.001*\"couldn\" + 0.001*\"sale\" + 0.001*\"comfort\" + 0.001*\"size\" + 0.001*\"anybodi\" + 0.001*\"stock\"\n",
            "Topic: 17 Word: 0.196*\"mainten\" + 0.034*\"adjust\" + 0.018*\"troubleshoot\" + 0.001*\"manual\" + 0.001*\"mcdonald\" + 0.001*\"activ\" + 0.001*\"pursu\" + 0.001*\"necessarili\" + 0.001*\"realiz\" + 0.001*\"program\"\n",
            "Topic: 18 Word: 0.097*\"macbook\" + 0.083*\"consult\" + 0.077*\"bilingu\" + 0.071*\"shirt\" + 0.065*\"perfectli\" + 0.018*\"wear\" + 0.017*\"greet\" + 0.017*\"manual\" + 0.016*\"back\" + 0.016*\"throw\"\n",
            "Topic: 19 Word: 0.001*\"term\" + 0.001*\"shut\" + 0.001*\"volunt\" + 0.001*\"ethic\" + 0.001*\"nerd\" + 0.001*\"pursu\" + 0.001*\"commun\" + 0.001*\"direct\" + 0.001*\"polit\" + 0.001*\"frustrat\"\n",
            "Topic: 20 Word: 0.003*\"hospit\" + 0.001*\"ladder\" + 0.001*\"post\" + 0.001*\"smile\" + 0.001*\"greatest\" + 0.001*\"definit\" + 0.001*\"secur\" + 0.001*\"perspect\" + 0.001*\"greet\" + 0.001*\"month\"\n",
            "Topic: 21 Word: 0.001*\"onlin\" + 0.001*\"conveni\" + 0.001*\"rang\" + 0.001*\"paint\" + 0.001*\"volunt\" + 0.001*\"account\" + 0.001*\"camp\" + 0.001*\"facebook\" + 0.001*\"grade\" + 0.001*\"angri\"\n",
            "Topic: 22 Word: 0.001*\"search\" + 0.001*\"challeng\" + 0.001*\"overal\" + 0.001*\"overcom\" + 0.001*\"adapt\" + 0.001*\"friendli\" + 0.001*\"graduat\" + 0.001*\"topic\" + 0.001*\"comput\" + 0.001*\"bodi\"\n",
            "Topic: 23 Word: 0.004*\"low\" + 0.002*\"total\" + 0.002*\"aisl\" + 0.001*\"drop\" + 0.001*\"factori\" + 0.001*\"star\" + 0.001*\"password\" + 0.001*\"network\" + 0.001*\"secur\" + 0.001*\"feedback\"\n",
            "Topic: 24 Word: 0.148*\"militari\" + 0.100*\"anytim\" + 0.061*\"verbal\" + 0.059*\"ton\" + 0.035*\"pressur\" + 0.021*\"scanner\" + 0.010*\"forklift\" + 0.009*\"orient\" + 0.008*\"solut\" + 0.007*\"master\"\n",
            "Topic: 25 Word: 0.061*\"mark\" + 0.012*\"advic\" + 0.003*\"photographi\" + 0.001*\"macbook\" + 0.001*\"consum\" + 0.001*\"bond\" + 0.001*\"schedul\" + 0.001*\"lock\" + 0.001*\"hardest\" + 0.001*\"basic\"\n",
            "Topic: 26 Word: 0.001*\"depot\" + 0.001*\"clean\" + 0.001*\"vibe\" + 0.001*\"paint\" + 0.001*\"challeng\" + 0.001*\"chanc\" + 0.001*\"cousin\" + 0.001*\"tough\" + 0.001*\"yeah\" + 0.001*\"role\"\n",
            "Topic: 27 Word: 0.065*\"ahead\" + 0.001*\"incorpor\" + 0.001*\"brother\" + 0.001*\"crew\" + 0.001*\"leadership\" + 0.001*\"holiday\" + 0.001*\"seek\" + 0.001*\"priorit\" + 0.001*\"staff\" + 0.001*\"appreci\"\n",
            "Topic: 28 Word: 0.001*\"correct\" + 0.001*\"wear\" + 0.001*\"path\" + 0.001*\"reliabl\" + 0.001*\"teach\" + 0.001*\"heavi\" + 0.001*\"bluetooth\" + 0.001*\"team\" + 0.001*\"whatnot\" + 0.001*\"report\"\n",
            "Topic: 29 Word: 0.200*\"crazi\" + 0.019*\"weird\" + 0.004*\"mechan\" + 0.001*\"liter\" + 0.001*\"friday\" + 0.001*\"tech\" + 0.001*\"accur\" + 0.001*\"resourc\" + 0.001*\"basic\" + 0.001*\"instanc\"\n",
            "Topic: 30 Word: 0.188*\"reliabl\" + 0.001*\"desk\" + 0.001*\"applianc\" + 0.001*\"ship\" + 0.001*\"success\" + 0.001*\"definit\" + 0.001*\"week\" + 0.001*\"depot\" + 0.001*\"sens\" + 0.001*\"clerk\"\n",
            "Topic: 31 Word: 0.008*\"actual\" + 0.007*\"team\" + 0.007*\"basic\" + 0.006*\"probabl\" + 0.006*\"goal\" + 0.006*\"mayb\" + 0.006*\"compani\" + 0.006*\"differ\" + 0.006*\"languag\" + 0.005*\"translat\"\n",
            "Topic: 32 Word: 0.121*\"memor\" + 0.070*\"ipad\" + 0.021*\"face\" + 0.018*\"greet\" + 0.011*\"brain\" + 0.010*\"wear\" + 0.007*\"sleep\" + 0.006*\"return\" + 0.005*\"accomplish\" + 0.001*\"teacher\"\n",
            "Topic: 33 Word: 0.053*\"troubleshoot\" + 0.045*\"fulfil\" + 0.042*\"total\" + 0.036*\"result\" + 0.034*\"accur\" + 0.029*\"trade\" + 0.029*\"everyday\" + 0.026*\"troubl\" + 0.026*\"advantag\" + 0.026*\"pair\"\n",
            "Topic: 34 Word: 0.001*\"success\" + 0.001*\"potenti\" + 0.001*\"teacher\" + 0.001*\"basebal\" + 0.001*\"loud\" + 0.001*\"wrong\" + 0.001*\"grade\" + 0.001*\"applianc\" + 0.001*\"basketbal\" + 0.001*\"aisl\"\n",
            "Topic: 35 Word: 0.002*\"keyboard\" + 0.001*\"fulli\" + 0.001*\"produc\" + 0.001*\"park\" + 0.001*\"art\" + 0.001*\"present\" + 0.001*\"inappropri\" + 0.001*\"polici\" + 0.001*\"idea\" + 0.001*\"privaci\"\n",
            "Topic: 36 Word: 0.001*\"gotta\" + 0.001*\"nation\" + 0.001*\"forklift\" + 0.001*\"graphic\" + 0.001*\"setup\" + 0.001*\"space\" + 0.001*\"memori\" + 0.001*\"woman\" + 0.001*\"tabl\" + 0.001*\"color\"\n",
            "Topic: 37 Word: 0.147*\"aris\" + 0.010*\"random\" + 0.004*\"soccer\" + 0.004*\"challeng\" + 0.003*\"advantag\" + 0.002*\"arriv\" + 0.002*\"fix\" + 0.001*\"googl\" + 0.001*\"advanc\" + 0.001*\"pandem\"\n",
            "Topic: 38 Word: 0.047*\"car\" + 0.023*\"multipl\" + 0.022*\"faster\" + 0.019*\"complet\" + 0.017*\"locat\" + 0.010*\"space\" + 0.004*\"appl\" + 0.001*\"skill\" + 0.001*\"weekend\" + 0.001*\"team\"\n",
            "Topic: 39 Word: 0.001*\"stool\" + 0.001*\"purpos\" + 0.001*\"basketbal\" + 0.001*\"send\" + 0.001*\"sport\" + 0.001*\"basebal\" + 0.001*\"shape\" + 0.001*\"savvi\" + 0.001*\"energi\" + 0.001*\"tool\"\n",
            "Topic: 40 Word: 0.108*\"challeng\" + 0.025*\"succeed\" + 0.022*\"station\" + 0.021*\"footbal\" + 0.002*\"constantli\" + 0.002*\"catch\" + 0.002*\"recogn\" + 0.002*\"aspect\" + 0.002*\"fight\" + 0.002*\"labor\"\n",
            "Topic: 41 Word: 0.001*\"awesom\" + 0.001*\"prefer\" + 0.001*\"ear\" + 0.001*\"weekend\" + 0.001*\"descript\" + 0.001*\"bilingu\" + 0.001*\"hike\" + 0.001*\"outdoor\" + 0.001*\"comfort\" + 0.001*\"fellow\"\n",
            "Topic: 42 Word: 0.001*\"batteri\" + 0.001*\"knock\" + 0.001*\"mobil\" + 0.001*\"descript\" + 0.001*\"sale\" + 0.001*\"zone\" + 0.001*\"fulfil\" + 0.001*\"educ\" + 0.001*\"qualifi\" + 0.001*\"privaci\"\n",
            "Topic: 43 Word: 0.001*\"network\" + 0.001*\"ladder\" + 0.001*\"fight\" + 0.001*\"hike\" + 0.001*\"heavi\" + 0.001*\"privaci\" + 0.001*\"box\" + 0.001*\"sell\" + 0.001*\"quiet\" + 0.001*\"challeng\"\n",
            "Topic: 44 Word: 0.012*\"tool\" + 0.004*\"manual\" + 0.003*\"apart\" + 0.003*\"chain\" + 0.003*\"memor\" + 0.002*\"confus\" + 0.001*\"print\" + 0.001*\"translat\" + 0.001*\"show\" + 0.001*\"cell\"\n",
            "Topic: 45 Word: 0.001*\"platform\" + 0.001*\"background\" + 0.001*\"satisfact\" + 0.001*\"realiz\" + 0.001*\"increas\" + 0.001*\"featur\" + 0.001*\"cybersecur\" + 0.001*\"job\" + 0.001*\"organ\" + 0.001*\"face\"\n",
            "Topic: 46 Word: 0.095*\"student\" + 0.072*\"teacher\" + 0.058*\"speed\" + 0.057*\"entertain\" + 0.056*\"wear\" + 0.049*\"memori\" + 0.047*\"citi\" + 0.043*\"orient\" + 0.035*\"separ\" + 0.034*\"troubl\"\n",
            "Topic: 47 Word: 0.068*\"pictur\" + 0.042*\"prioriti\" + 0.035*\"individu\" + 0.030*\"print\" + 0.027*\"server\" + 0.026*\"frame\" + 0.024*\"trade\" + 0.023*\"transfer\" + 0.022*\"gentleman\" + 0.015*\"hesit\"\n",
            "Topic: 48 Word: 0.165*\"kitchen\" + 0.141*\"hike\" + 0.113*\"town\" + 0.008*\"equal\" + 0.006*\"loud\" + 0.005*\"box\" + 0.001*\"lay\" + 0.001*\"camp\" + 0.001*\"reliabl\" + 0.001*\"brain\"\n",
            "Topic: 49 Word: 0.128*\"incom\" + 0.011*\"face\" + 0.001*\"appropri\" + 0.001*\"factori\" + 0.001*\"forklift\" + 0.001*\"flow\" + 0.001*\"manner\" + 0.001*\"view\" + 0.001*\"drive\" + 0.001*\"teamwork\"\n",
            "Topic: 50 Word: 0.001*\"bank\" + 0.001*\"cabl\" + 0.001*\"boss\" + 0.001*\"suggest\" + 0.001*\"truck\" + 0.001*\"troubl\" + 0.001*\"foremost\" + 0.001*\"versu\" + 0.001*\"soon\" + 0.001*\"articl\"\n",
            "Topic: 51 Word: 0.138*\"expertis\" + 0.006*\"trade\" + 0.004*\"consult\" + 0.001*\"adjust\" + 0.001*\"throw\" + 0.001*\"financi\" + 0.001*\"amazon\" + 0.001*\"educ\" + 0.001*\"event\" + 0.001*\"coach\"\n",
            "Topic: 52 Word: 0.134*\"lunch\" + 0.115*\"brain\" + 0.056*\"applianc\" + 0.016*\"depot\" + 0.010*\"foot\" + 0.010*\"select\" + 0.009*\"pain\" + 0.007*\"fulfil\" + 0.007*\"procedur\" + 0.006*\"verbal\"\n",
            "Topic: 53 Word: 0.040*\"ethic\" + 0.026*\"laugh\" + 0.012*\"everyday\" + 0.002*\"teamwork\" + 0.002*\"slow\" + 0.001*\"includ\" + 0.001*\"throw\" + 0.001*\"confront\" + 0.001*\"felt\" + 0.001*\"sport\"\n",
            "Topic: 54 Word: 0.023*\"reward\" + 0.001*\"construct\" + 0.001*\"machin\" + 0.001*\"daughter\" + 0.001*\"swim\" + 0.001*\"atmospher\" + 0.001*\"respons\" + 0.001*\"extra\" + 0.001*\"random\" + 0.001*\"newest\"\n",
            "Topic: 55 Word: 0.002*\"church\" + 0.002*\"vibe\" + 0.001*\"atmospher\" + 0.001*\"accomplish\" + 0.001*\"result\" + 0.001*\"shirt\" + 0.001*\"ladder\" + 0.001*\"wear\" + 0.001*\"bore\" + 0.001*\"middl\"\n",
            "Topic: 56 Word: 0.001*\"pain\" + 0.001*\"belt\" + 0.001*\"outgo\" + 0.001*\"corpor\" + 0.001*\"normal\" + 0.001*\"lay\" + 0.001*\"rel\" + 0.001*\"motherboard\" + 0.001*\"total\" + 0.001*\"difficult\"\n",
            "Topic: 57 Word: 0.136*\"versu\" + 0.078*\"procedur\" + 0.029*\"jack\" + 0.028*\"find\" + 0.026*\"determin\" + 0.025*\"iphon\" + 0.023*\"resolv\" + 0.018*\"ride\" + 0.017*\"public\" + 0.015*\"outdoor\"\n",
            "Topic: 58 Word: 0.103*\"soccer\" + 0.029*\"monitor\" + 0.029*\"rate\" + 0.022*\"colleg\" + 0.021*\"mechan\" + 0.020*\"android\" + 0.019*\"student\" + 0.013*\"major\" + 0.002*\"target\" + 0.001*\"display\"\n",
            "Topic: 59 Word: 0.001*\"assur\" + 0.001*\"older\" + 0.001*\"swim\" + 0.001*\"ear\" + 0.001*\"pandem\" + 0.001*\"hike\" + 0.001*\"hospit\" + 0.001*\"outdoor\" + 0.001*\"board\" + 0.001*\"neg\"\n",
            "Topic: 60 Word: 0.103*\"select\" + 0.008*\"safeti\" + 0.006*\"forklift\" + 0.004*\"exact\" + 0.003*\"wear\" + 0.002*\"assign\" + 0.002*\"outgo\" + 0.001*\"detail\" + 0.001*\"caus\" + 0.001*\"out\"\n",
            "Topic: 61 Word: 0.123*\"public\" + 0.105*\"wast\" + 0.014*\"box\" + 0.004*\"ladder\" + 0.003*\"spare\" + 0.002*\"wife\" + 0.002*\"ring\" + 0.002*\"smoother\" + 0.002*\"art\" + 0.002*\"wire\"\n",
            "Topic: 62 Word: 0.116*\"inappropri\" + 0.027*\"quiet\" + 0.026*\"vacat\" + 0.023*\"medic\" + 0.023*\"mechan\" + 0.022*\"challeng\" + 0.022*\"orient\" + 0.021*\"teamwork\" + 0.021*\"return\" + 0.019*\"earlier\"\n",
            "Topic: 63 Word: 0.001*\"polit\" + 0.001*\"listen\" + 0.001*\"serv\" + 0.001*\"challeng\" + 0.001*\"tough\" + 0.001*\"advic\" + 0.001*\"employe\" + 0.001*\"industri\" + 0.001*\"vehicl\" + 0.001*\"opinion\"\n",
            "Topic: 64 Word: 0.108*\"camp\" + 0.094*\"maintain\" + 0.092*\"partner\" + 0.073*\"weekend\" + 0.018*\"discount\" + 0.017*\"friday\" + 0.015*\"wear\" + 0.014*\"verbal\" + 0.013*\"fulfil\" + 0.010*\"ladder\"\n",
            "Topic: 65 Word: 0.001*\"car\" + 0.001*\"camera\" + 0.001*\"cut\" + 0.001*\"treat\" + 0.001*\"road\" + 0.001*\"solut\" + 0.001*\"grind\" + 0.001*\"prioriti\" + 0.001*\"perspect\" + 0.001*\"empathi\"\n",
            "Topic: 66 Word: 0.002*\"consol\" + 0.001*\"invest\" + 0.001*\"except\" + 0.001*\"launch\" + 0.001*\"photographi\" + 0.001*\"languag\" + 0.001*\"articl\" + 0.001*\"electron\" + 0.001*\"public\" + 0.001*\"purchas\"\n",
            "Topic: 67 Word: 0.001*\"act\" + 0.001*\"amazon\" + 0.001*\"remain\" + 0.001*\"ship\" + 0.001*\"doubl\" + 0.001*\"tend\" + 0.001*\"warehous\" + 0.001*\"night\" + 0.001*\"number\" + 0.001*\"pack\"\n",
            "Topic: 68 Word: 0.001*\"initi\" + 0.001*\"processor\" + 0.001*\"overtim\" + 0.001*\"mark\" + 0.001*\"regardless\" + 0.001*\"graphic\" + 0.001*\"card\" + 0.001*\"teamwork\" + 0.001*\"nice\" + 0.001*\"produc\"\n",
            "Topic: 69 Word: 0.119*\"out\" + 0.118*\"content\" + 0.033*\"babi\" + 0.014*\"challeng\" + 0.007*\"applianc\" + 0.007*\"privaci\" + 0.004*\"apart\" + 0.001*\"hospit\" + 0.001*\"fascin\" + 0.001*\"accomplish\"\n",
            "Topic: 70 Word: 0.001*\"twitter\" + 0.001*\"task\" + 0.001*\"industri\" + 0.001*\"interact\" + 0.001*\"teamwork\" + 0.001*\"complet\" + 0.001*\"music\" + 0.001*\"usual\" + 0.001*\"goal\" + 0.001*\"posit\"\n",
            "Topic: 71 Word: 0.001*\"forklift\" + 0.001*\"reli\" + 0.001*\"suppos\" + 0.001*\"machin\" + 0.001*\"energi\" + 0.001*\"storag\" + 0.001*\"appl\" + 0.001*\"edit\" + 0.001*\"interact\" + 0.001*\"water\"\n",
            "Topic: 72 Word: 0.001*\"plu\" + 0.001*\"brain\" + 0.001*\"honestli\" + 0.001*\"clock\" + 0.001*\"out\" + 0.001*\"car\" + 0.001*\"senior\" + 0.001*\"lead\" + 0.001*\"reliabl\" + 0.001*\"call\"\n",
            "Topic: 73 Word: 0.096*\"factori\" + 0.025*\"pressur\" + 0.010*\"player\" + 0.010*\"select\" + 0.009*\"bother\" + 0.009*\"doubl\" + 0.009*\"speed\" + 0.006*\"normal\" + 0.004*\"speaker\" + 0.004*\"separ\"\n",
            "Topic: 74 Word: 0.108*\"art\" + 0.026*\"teamwork\" + 0.021*\"compliment\" + 0.019*\"swim\" + 0.018*\"certifi\" + 0.017*\"vacat\" + 0.017*\"master\" + 0.016*\"till\" + 0.011*\"sleep\" + 0.011*\"project\"\n",
            "Topic: 75 Word: 0.001*\"door\" + 0.001*\"adapt\" + 0.001*\"instal\" + 0.001*\"provid\" + 0.001*\"unload\" + 0.001*\"xbox\" + 0.001*\"content\" + 0.001*\"reliabl\" + 0.001*\"visual\" + 0.001*\"hand\"\n",
            "Topic: 76 Word: 0.126*\"friday\" + 0.121*\"black\" + 0.013*\"imagin\" + 0.001*\"headset\" + 0.001*\"softwar\" + 0.001*\"superior\" + 0.001*\"procedur\" + 0.001*\"offic\" + 0.001*\"repres\" + 0.001*\"method\"\n",
            "Topic: 77 Word: 0.158*\"star\" + 0.001*\"kitchen\" + 0.001*\"public\" + 0.001*\"daughter\" + 0.001*\"out\" + 0.001*\"brain\" + 0.001*\"switch\" + 0.001*\"protect\" + 0.001*\"respect\" + 0.001*\"medic\"\n",
            "Topic: 78 Word: 0.001*\"desktop\" + 0.001*\"headphon\" + 0.001*\"offic\" + 0.001*\"rat\" + 0.001*\"scar\" + 0.001*\"bigger\" + 0.001*\"necessari\" + 0.001*\"control\" + 0.001*\"expertis\" + 0.001*\"adapt\"\n",
            "Topic: 79 Word: 0.063*\"rude\" + 0.001*\"televis\" + 0.001*\"updat\" + 0.001*\"truth\" + 0.001*\"activ\" + 0.001*\"everyday\" + 0.001*\"add\" + 0.001*\"test\" + 0.001*\"exactli\" + 0.001*\"iphon\"\n",
            "Topic: 80 Word: 0.001*\"bear\" + 0.001*\"wire\" + 0.001*\"electr\" + 0.001*\"equip\" + 0.001*\"travel\" + 0.001*\"origin\" + 0.001*\"unload\" + 0.001*\"appl\" + 0.001*\"ladder\" + 0.001*\"enjoy\"\n",
            "Topic: 81 Word: 0.214*\"ladder\" + 0.113*\"equal\" + 0.026*\"vehicl\" + 0.011*\"prove\" + 0.005*\"shut\" + 0.003*\"graphic\" + 0.003*\"uncomfort\" + 0.002*\"window\" + 0.002*\"launch\" + 0.001*\"lay\"\n",
            "Topic: 82 Word: 0.001*\"goal\" + 0.001*\"accomplish\" + 0.001*\"whatnot\" + 0.001*\"mcdonald\" + 0.001*\"friendli\" + 0.001*\"switch\" + 0.001*\"pick\" + 0.001*\"teamwork\" + 0.001*\"longer\" + 0.001*\"proceed\"\n",
            "Topic: 83 Word: 0.021*\"solut\" + 0.020*\"unload\" + 0.019*\"valu\" + 0.018*\"reach\" + 0.017*\"relationship\" + 0.016*\"advic\" + 0.016*\"pull\" + 0.014*\"normal\" + 0.014*\"load\" + 0.012*\"regist\"\n",
            "Topic: 84 Word: 0.112*\"desktop\" + 0.033*\"monitor\" + 0.019*\"express\" + 0.014*\"student\" + 0.007*\"cool\" + 0.006*\"forklift\" + 0.003*\"drive\" + 0.002*\"test\" + 0.001*\"truck\" + 0.001*\"paper\"\n",
            "Topic: 85 Word: 0.014*\"iphon\" + 0.014*\"discuss\" + 0.013*\"proud\" + 0.013*\"camera\" + 0.012*\"break\" + 0.012*\"depart\" + 0.012*\"graphic\" + 0.011*\"movi\" + 0.011*\"moment\" + 0.011*\"easi\"\n",
            "Topic: 86 Word: 0.001*\"employe\" + 0.001*\"slow\" + 0.001*\"lot\" + 0.001*\"listen\" + 0.001*\"understand\" + 0.001*\"feedback\" + 0.001*\"interact\" + 0.001*\"let\" + 0.001*\"advanc\" + 0.001*\"take\"\n",
            "Topic: 87 Word: 0.001*\"server\" + 0.001*\"vacat\" + 0.001*\"huge\" + 0.001*\"skill\" + 0.001*\"squad\" + 0.001*\"geek\" + 0.001*\"normal\" + 0.001*\"make\" + 0.001*\"outdoor\" + 0.001*\"technic\"\n",
            "Topic: 88 Word: 0.133*\"manual\" + 0.018*\"eas\" + 0.015*\"orient\" + 0.001*\"greet\" + 0.001*\"seek\" + 0.001*\"knee\" + 0.001*\"concern\" + 0.001*\"continu\" + 0.001*\"accomplish\" + 0.001*\"lose\"\n",
            "Topic: 89 Word: 0.001*\"nurs\" + 0.001*\"program\" + 0.001*\"belt\" + 0.001*\"class\" + 0.001*\"mistak\" + 0.001*\"packag\" + 0.001*\"polici\" + 0.001*\"feedback\" + 0.001*\"colleg\" + 0.001*\"happi\"\n",
            "Topic: 90 Word: 0.088*\"throw\" + 0.072*\"creativ\" + 0.069*\"ensur\" + 0.058*\"imag\" + 0.058*\"roll\" + 0.052*\"qualifi\" + 0.042*\"round\" + 0.041*\"afraid\" + 0.029*\"gentleman\" + 0.023*\"asset\"\n",
            "Topic: 91 Word: 0.042*\"ignor\" + 0.022*\"mcdonald\" + 0.021*\"serv\" + 0.020*\"rest\" + 0.010*\"happi\" + 0.002*\"car\" + 0.001*\"nurs\" + 0.001*\"month\" + 0.001*\"music\" + 0.001*\"shoot\"\n",
            "Topic: 92 Word: 0.004*\"smart\" + 0.002*\"entertain\" + 0.002*\"everyday\" + 0.001*\"feedback\" + 0.001*\"atmospher\" + 0.001*\"late\" + 0.001*\"pocket\" + 0.001*\"appli\" + 0.001*\"teamwork\" + 0.001*\"basebal\"\n",
            "Topic: 93 Word: 0.001*\"pass\" + 0.001*\"lunch\" + 0.001*\"care\" + 0.001*\"goal\" + 0.001*\"probabl\" + 0.001*\"encourag\" + 0.001*\"twitter\" + 0.001*\"mess\" + 0.001*\"appl\" + 0.001*\"offer\"\n",
            "Topic: 94 Word: 0.001*\"tend\" + 0.001*\"extens\" + 0.001*\"lead\" + 0.001*\"owner\" + 0.001*\"challeng\" + 0.001*\"entertain\" + 0.001*\"attitud\" + 0.001*\"holiday\" + 0.001*\"comfort\" + 0.001*\"shop\"\n",
            "Topic: 95 Word: 0.002*\"bother\" + 0.001*\"friday\" + 0.001*\"wear\" + 0.001*\"movi\" + 0.001*\"packag\" + 0.001*\"laptop\" + 0.001*\"secur\" + 0.001*\"boss\" + 0.001*\"qualifi\" + 0.001*\"mark\"\n",
            "Topic: 96 Word: 0.001*\"result\" + 0.001*\"film\" + 0.001*\"produc\" + 0.001*\"program\" + 0.001*\"evolv\" + 0.001*\"individu\" + 0.001*\"wake\" + 0.001*\"client\" + 0.001*\"expect\" + 0.001*\"passion\"\n",
            "Topic: 97 Word: 0.001*\"target\" + 0.001*\"unprofession\" + 0.001*\"bank\" + 0.001*\"judg\" + 0.001*\"teamwork\" + 0.001*\"tool\" + 0.001*\"decid\" + 0.001*\"true\" + 0.001*\"hasn\" + 0.001*\"speaker\"\n",
            "Topic: 98 Word: 0.001*\"refer\" + 0.001*\"slowli\" + 0.001*\"foot\" + 0.001*\"interpret\" + 0.001*\"resolv\" + 0.001*\"master\" + 0.001*\"degre\" + 0.001*\"wast\" + 0.001*\"fight\" + 0.001*\"express\"\n",
            "Topic: 99 Word: 0.001*\"judg\" + 0.001*\"instruct\" + 0.001*\"wall\" + 0.001*\"activ\" + 0.001*\"outdoor\" + 0.001*\"vacat\" + 0.001*\"overcom\" + 0.001*\"higher\" + 0.001*\"line\" + 0.001*\"coach\"\n"
          ]
        }
      ]
    }
  ]
}